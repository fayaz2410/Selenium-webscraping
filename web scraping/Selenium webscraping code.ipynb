{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from selenium import webdriver  # For automating web browser interactions\n",
    "from selenium.webdriver.common.by import By  # For locating elements\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # For waiting until certain conditions are met\n",
    "from selenium.webdriver.support import expected_conditions as EC  # For defining expected conditions for waiting\n",
    "from bs4 import BeautifulSoup  # For parsing HTML content\n",
    "import time  # For adding delays\n",
    "import pandas as pd  # For handling data in a tabular format\n",
    "\n",
    "# Initializing a Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigating to the webpage containing financial data\n",
    "driver.get('https://finance.yahoo.com/quote/GOEV/financials')\n",
    "\n",
    "# Adding a delay to allow time for the page to load (2 seconds in this case)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    # Waiting for a specific button to be present and clickable on the page\n",
    "    button = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '//*[@id=\"Col1-1-Financials-Proxy\"]/section/div[3]'))\n",
    "    )\n",
    "    \n",
    "    # Extracting the HTML source code of the page after the button is visible\n",
    "    new_html = driver.page_source\n",
    "    \n",
    "    # Parsing the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(new_html, 'html.parser')\n",
    "finally:\n",
    "    # Closing the browser window to free up system resources\n",
    "    driver.quit()\n",
    "\n",
    "# Finding the table headers\n",
    "tablehead = soup.find('div', class_='D(tbhg)')\n",
    "world_titles = tablehead.find_all('span')\n",
    "world_table_titles = [title.text.strip() for title in world_titles]\n",
    "\n",
    "# Creating an empty DataFrame with column names extracted from table headers\n",
    "df = pd.DataFrame(columns=world_table_titles)\n",
    "\n",
    "# Finding table rows\n",
    "tablerow = soup.find('div', class_='D(tbrg)')\n",
    "\n",
    "# Looping through each row and extracting data\n",
    "for row in tablerow:\n",
    "    rd = row.find_all('span')\n",
    "    ird = [data.text.strip() for data in rd]\n",
    "    \n",
    "    # Checking if the length of extracted data matches the length of table headers\n",
    "    if len(ird) == len(world_table_titles):\n",
    "        # Appending data to DataFrame if it's of the expected length\n",
    "        df.loc[len(df)] = ird\n",
    "\n",
    "# Displaying DataFrame containing extracted financial data\n",
    "df\n",
    "\n",
    "# Saving DataFrame to a CSV file\n",
    "df.to_csv(r\"C:\\Users\\bhuky\\OneDrive\\Desktop\\web scraping\\output.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
